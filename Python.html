<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
	<title>  
	  
  	Python - MagicalRice的Blog
  	
	</title>

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

	<link href="atom.xml" rel="alternate" title="MagicalRice的Blog" type="application/atom+xml">

	<link href="asset/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<link href="asset/stylesheets/font-awesome.min.css" media="screen, projection" rel="stylesheet" type="text/css">
	<script src="asset/javascripts/jquery.min.js"></script>
	<script src="asset/highlightjs/highlight.pack.js"></script>
	<link href="asset/highlightjs/styles/solarized_dark.css" media="screen, projection" rel="stylesheet" type="text/css">
<script>hljs.initHighlightingOnLoad();</script>

	<!--[if lt IE 9]><script src="asset/javascripts/html5.js"></script><![endif]-->
	<!-- <link href='http://fonts.googleapis.com/css?family=Nunito:400,300,700' rel='stylesheet' type='text/css'> -->
	<style type="text/css">
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 300;
  src: local('Nunito-Light'), url(asset/font/1TiHc9yag0wq3lDO9cw0voX0hVgzZQUfRDuZrPvH3D8.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 400;
  src: local('Nunito-Regular'), url(asset/font/6TbRXKWJjpj6V2v_WyRbMX-_kf6ByYO6CLYdB4HQE-Y.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 700;
  src: local('Nunito-Bold'), url(asset/font/TttUCfJ272GBgSKaOaD7KoX0hVgzZQUfRDuZrPvH3D8.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
	</style>
	
	<style type="text/css">
	.container .left-col{ opacity: 1;}
	#pagenavi a{ font-size: 1.3em;}
	#pagenavi .next:before{ top: 3px;}
	#pagenavi .prev:before{ top: 3px;}
	.container .mid-col .mid-col-container #content .archives .title{ font-size: 1.5em;}
	.container .mid-col .mid-col-container #content article{ padding: 15px 0px;}
	#header .subtitle {
		line-height: 1.2em;
		padding-top: 8px;
	}
	article pre{ background: none; border: none; padding: 0;}
	article .entry-content{text-align: left;}
	.share-comment{ padding: 25px 0px; clear: both;}
	hr{ margin: 20px 0px;border: 0; border-top:solid 1px #ddd;}
	</style>
  

</head>


<body>
	<div class="container">
		<div class="left-col">
			<div class="intrude-less">
				<header id="header" class="inner">
				 
					
					<h1><a href="index.html">MagicalRice的Blog</a></h1>
					<p class="subtitle">技术博客</p>
					<nav id="main-nav">
						<ul class="main">
						
						  <li id=""><a target="self" href="index.html">Home</a></li>
						
						  <li id=""><a target="_self" href="archives.html">Archives</a></li>
						
						</ul>
					</nav>

					<nav id="sub-nav">
						<div class="social">













								

								<a class="rss" href="atom.xml" title="RSS">RSS</a>
							
						</div>
					</nav>
				</header>				
			</div>
		</div>	
		<div class="mid-col">
			<div class="mid-col-container"> <div id="content" class="inner">
<div itemscope itemtype="http://schema.org/Blog">


	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2017-03-27T22:51:26+08:00" itemprop="datePublished">2017/3/27</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='Python.html'>Python</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="15561207869218.html" itemprop="url">
		Python学习笔记</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h2 id="toc_0">前言</h2>

<p>由于写毕设要搭建后端爬虫的需求，所以开始学习Python语言。由于没有系统的学习，所以笔记可能会记得比较散乱，有时间会一一整理，把一些重要的学习知识点记下来。当然有时间也会整理基础知识。</p>

<h2 id="toc_1">安装 Python</h2>

<h3 id="toc_2">升级pip</h3>

<p><code>pip3 install --upgrade pip</code></p>

<h2 id="toc_3">安装 Python 虚拟环境</h2>

<p><code>(sudo) pip3 install virtualenv virtualenvwrapper</code>  </p>

<p>修改<code>~/.bash_profile</code>,添加以下语句  </p>

<pre class="line-numbers"><code class="language-text">export WORKON_HOME=$HOME/.virtualenvs
export PROJECT_HOME=$HOME/workspace
source /usr/local/bin/virtualenvwrapper.sh
</code></pre>

<p>修改后使之立即生效(也可以重启终端使之生效)：<br/><br/>
<code>source ~/.bash_profile</code>  </p>

<h3 id="toc_4">基本用法</h3>

<h4 id="toc_5">1、创建一个虚拟开发环境</h4>

<p><code>mkvirtualenv zqxt：创建运行环境zqxt</code><br/><br/>
<code>workon zqxt: 工作在 zqxt 环境 或 从其它环境切换到 zqxt 环境</code><br/><br/>
<code>deactivate: 退出终端环境</code><br/><br/>
其它的： <br/>
<code>rmvirtualenv ENV：删除运行环境ENV</code><br/><br/>
<code>mkproject mic：创建mic项目和运行环境mic</code><br/><br/>
<code>mktmpenv：创建临时运行环境</code><br/><br/>
<code>lsvirtualenv: 列出可用的运行环境</code><br/><br/>
<code>lssitepackages: 列出当前环境安装了的包</code><br/><br/>
创建的环境是独立的，互不干扰，无需sudo权限即可使用 pip 来进行包的管理。  </p>

<p>完成后在当前目录会创建一个test_env的文件夹，进入文件夹会发现生成了以下的目录，神奇吧  </p>

<pre class="line-numbers"><code class="language-text">├── bin
├── include
│   └── python2.7
├── lib
│   └── python2.7       //所有的新包会被存在这
│       ├── distutils
│       ├── encodings
│       ├── lib-dynload
│       └── site-packages
├── local
│   ├── bin
│   ├── include
│   └── lib
</code></pre>

<h2 id="toc_6">安装Django</h2>

<p><code>pip3 install Django</code>或者<code>pip install Django==1.10.6</code><br/><br/>
在终端上输入Python,点击Enter,进入Python环境</p>

<pre class="line-numbers"><code class="language-text">&gt;&gt;&gt; import django
&gt;&gt;&gt; django.VERSION
(1, 8, 16, &#39;final&#39;, 0)
&gt;&gt;&gt; 
&gt;&gt;&gt; django.get_version()
&#39;1.8.16&#39;
</code></pre>

<p>这样就可以看见安装的django的版本号</p>

<h3 id="toc_7">安装django-Celery，设置调度计划任务</h3>

<p><code>pip3 install django-celery</code></p>

<h3 id="toc_8">安装PIL（Python Imaging Library）</h3>

<p>图片处理的扩展包:<br/>
<code>brew install jpeg    #安装</code></p>

<h3 id="toc_9">安装Django-Dynamic-Scraper(DDS)</h3>

<p><code>pip3 install django-dynamic-scraper</code><br/><br/>
<code>pip3 install scrapy-splash</code><br/>
<code>pip3 install scrapy-djangoitem</code></p>

<h2 id="toc_10">安装scrapy</h2>

<p><code>pip3 install Scrapy 安装Scrapy</code>或者<code>pip3 install scrapy==1.3.3</code>  </p>

<h2 id="toc_11">安装chardet-检测网页编码</h2>

<p><code>pip3 install chardet  #安装chardet</code>  </p>

<pre class="line-numbers"><code class="language-python">def GetHtml( url):  
    page = urllib.request.urlopen(url)  
    contex = page.read()  
    return contex  

print(sys.getfilesystemencoding())    #本地系统编码
print(&#39;Html is encoding by : %&#39;,chardet.detect(GetHtml(url))) #网页编码
</code></pre>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2017-03-15T14:04:26+08:00" itemprop="datePublished">2017/3/15</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='Python.html'>Python</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="15561207869076.html" itemprop="url">
		Python-Crawler</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h2 id="toc_0">总文件</h2>

<pre class="line-numbers"><code class="language-python">import scrapy
from scrapy.selector import Selector
from scrapy.http import HtmlResponse

class QuotesSpider(scrapy.Spider):
    name = &quot;quotes&quot;

    def start_requests(self):
        urls = [
            &#39;http://www.xujc.com.cn/&#39;,
        ]
        for url in urls:
            yield scrapy.Request(url=url, callback=self.parse)

    def parse(self,response):
        sel = Selector(response)
        sties = sel.xpath(&#39;//table&#39;)
        # for site in sties:
        #   title = site.xpath(&#39;tr/td&#39;).extract()
        #   print(site)
        #   print(title)

        #filename = &#39;school-%s.html&#39; % 1
        #with open(filename, &#39;wb&#39;) as f:
             #f.write(contents)
        #self.log(&#39;Saved file %s&#39; % filename)
</code></pre>

<h2 id="toc_1">重点关注链接and标题</h2>

<pre class="line-numbers"><code class="language-python">import scrapy
from scrapy.selector import Selector
from scrapy.http import HtmlResponse

class QuotesSpider(scrapy.Spider):
    name = &quot;quotes&quot;

    def start_requests(self):
        urls = [
            &#39;http://www.xujc.com.cn/&#39;,
        ]
        for url in urls:
            yield scrapy.Request(url=url, callback=self.parse)

    def parse(self,response):
        sel = Selector(response)
        sties = sel.xpath(&#39;//table&#39;)

        title = sties[16].xpath(&#39;tr/td/a/text() | tr/td/a/@href | tr/td/text()&#39;).extract()
        print(sties[10])
        print(title)
</code></pre>

<h2 id="toc_2">日期时间</h2>

<pre class="line-numbers"><code class="language-python">title = sties[25].xpath(&#39;tr/td/table/tr/td[@id=&quot;zb&quot;]/table/tr/td/span/text()&#39;).extract()
        print(sties[10])
        print(title)
</code></pre>

<h2 id="toc_3">通知公告</h2>

<pre class="line-numbers"><code class="language-python">import scrapy
from scrapy.selector import Selector
from scrapy.http import HtmlResponse

class QuotesSpider(scrapy.Spider):
    name = &quot;quotes&quot;

    def start_requests(self):
        urls = [
            &#39;http://www.xujc.com.cn/index.php?c=Article&amp;a=idxnews&amp;lx=notice&#39;,
        ]
        for url in urls:
            yield scrapy.Request(url=url, callback=self.parse)

    def parse(self,response):
        sel = Selector(response)
        sties = sel.xpath(&#39;/html/body/table/tr&#39;)
        for site in sties:
            title = site.xpath(&#39;td/a/@href | td/a/text()&#39;).extract()
            print(site)
            print(title)
</code></pre>

<h2 id="toc_4">新闻中心</h2>

<pre class="line-numbers"><code class="language-python">import scrapy
from scrapy.selector import Selector
from scrapy.http import HtmlResponse

class QuotesSpider(scrapy.Spider):
    name = &quot;quotes&quot;

    def start_requests(self):
        urls = [
            &#39;http://www.xujc.com.cn/index.php?c=Article&amp;a=idxnews&amp;lx=news&#39;,
        ]
        for url in urls:
            yield scrapy.Request(url=url, callback=self.parse)

    def parse(self,response):
        sel = Selector(response)
        sties = sel.xpath(&#39;/html/body/ul/li&#39;)
        for site in sties:
            title = site.xpath(&#39;a/@href | a/text()&#39;).extract()
            print(site)
            print(title)
</code></pre>


			
			
		</div>

	</article>
  

</div>
<nav id="pagenavi">
	 
	
	<div class="center"><a href="archives.html">Blog Archives</a></div>

</nav>

</div>



        </div>
			<footer id="footer" class="inner">Copyright &copy; 2014
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a> &nbsp;&nbsp; 
Theme by <a href="http://shashankmehta.in/archive/2012/greyshade.html">Shashank Mehta</a>
      </footer>
		</div>
	</div>

  
    

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

</body>
</html>